{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyPqGxvK9qZP+aHiMqCk3YYh",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Subhanshu-2411/Iris_Detection-Tensorflow/blob/main/data.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "9XcACv1A1VsR"
      },
      "outputs": [],
      "source": [
        "!pip install labelme tensorflow opencv-python matplotlib albumentations --quiet"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import time\n",
        "import uuid\n",
        "import cv2\n",
        "import tensorflow as tf\n",
        "import cv2\n",
        "import json\n",
        "import numpy as np\n",
        "from matplotlib import pyplot as plt\n",
        "import albumentations as alb\n",
        "from google.colab import drive\n",
        "%matplotlib inline"
      ],
      "metadata": {
        "id": "_tjvu8OL1kKb"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "drive.mount('/gdrive')\n",
        "%cd /gdrive"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7qMNcoZ21yBY",
        "outputId": "4620c181-e305-4901-fe8d-e20841af5ec2"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /gdrive\n",
            "/gdrive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "IMAGE_PATH = '/gdrive/My Drive/Iris Detection/data/'\n",
        "number_images = 80"
      ],
      "metadata": {
        "id": "VBwGPV-92Lpo"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cap = cv2.VideoCapture(0)\n",
        "for imgnum in range(number_images):\n",
        "    print('Collecting image {}'.format(imgnum))\n",
        "    ret, frame = cap.read()\n",
        "    imgname = os.path.join(IMAGE_PATH,f'{str(uuid.uuid1())}.jpg')\n",
        "    if not cap.isOpened():\n",
        "      break\n",
        "    cv2.imwrite(imgname, frame)\n",
        "    cv2.imshow('frame', frame)\n",
        "    time.sleep(0.5)\n",
        "\n",
        "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
        "        break\n",
        "cap.release()\n",
        "cv2.destroyAllWindows()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kKicm63v2_bF",
        "outputId": "4ea90219-4668-4ffa-84c0-bfe663cd0c5f"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting image 0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
        "for gpu in gpus: \n",
        "    tf.config.experimental.set_memory_growth(gpu, True)"
      ],
      "metadata": {
        "id": "piDlptuU6QzR"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def load_image(x): \n",
        "    byte_img = tf.io.read_file(x)\n",
        "    img = tf.io.decode_jpeg(byte_img)\n",
        "    return img"
      ],
      "metadata": {
        "id": "Moop9re36S6z"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for folder in ['train','test','val']:\n",
        "    for file in os.listdir(os.path.join('data', folder, 'images')):\n",
        "        \n",
        "        filename = file.split('.')[0]+'.json'\n",
        "        existing_filepath = os.path.join('data','labels', filename)\n",
        "        if os.path.exists(existing_filepath): \n",
        "            new_filepath = os.path.join('data',folder,'labels',filename)\n",
        "            os.replace(existing_filepath, new_filepath)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 235
        },
        "id": "_dqg0n4p6e5S",
        "outputId": "1bf4fa71-dc62-4846-f120-2982cb0afeba"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-21-6548adeac4ec>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mfolder\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'train'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'test'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'val'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mfile\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'data'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfolder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'images'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m         \u001b[0mfilename\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'.'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'.json'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0mexisting_filepath\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'data'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'labels'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'data/train/images'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "augmentor = alb.Compose([alb.RandomCrop(width=450, height=450), \n",
        "                         alb.HorizontalFlip(p=0.5), \n",
        "                         alb.RandomBrightnessContrast(p=0.2),\n",
        "                         alb.RandomGamma(p=0.2), \n",
        "                         alb.RGBShift(p=0.2), \n",
        "                         alb.VerticalFlip(p=0.5)], \n",
        "                        keypoint_params=alb.KeypointParams(format='xy', label_fields=['class_labels']))"
      ],
      "metadata": {
        "id": "34FR5Q536l-i"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for partition in ['train', 'test', 'val']: \n",
        "    for image in os.listdir(os.path.join('data', partition, 'images')):\n",
        "        img = cv2.imread(os.path.join('data', partition, 'images', image))\n",
        "\n",
        "        classes = [0,0]\n",
        "        coords = [0,0,0.00001,0.00001]\n",
        "        label_path = os.path.join('data', partition, 'labels', f'{image.split(\".\")[0]}.json')\n",
        "        if os.path.exists(label_path):\n",
        "            with open(label_path, 'r') as f:\n",
        "                label = json.load(f)\n",
        "    \n",
        "            if label['shapes'][0]['label']=='LeftEye': \n",
        "                classes[0] = 1\n",
        "                coords[0] = np.squeeze(label['shapes'][0]['points'])[0]\n",
        "                coords[1] = np.squeeze(label['shapes'][0]['points'])[1]\n",
        "\n",
        "            if label['shapes'][0]['label']=='RightEye':\n",
        "                classes[1] = 1\n",
        "                coords[2] = np.squeeze(label['shapes'][0]['points'])[0]\n",
        "                coords[3] = np.squeeze(label['shapes'][0]['points'])[1]\n",
        "\n",
        "            if len(label['shapes']) > 1:     \n",
        "                if label['shapes'][1]['label'] =='LeftEye': \n",
        "                    classes[0] = 1 \n",
        "                    coords[0] = np.squeeze(label['shapes'][1]['points'])[0]\n",
        "                    coords[1] = np.squeeze(label['shapes'][1]['points'])[1]\n",
        "\n",
        "                if label['shapes'][1]['label'] =='RightEye': \n",
        "                    classes[1] = 1\n",
        "                    coords[2] = np.squeeze(label['shapes'][1]['points'])[0]\n",
        "                    coords[3] = np.squeeze(label['shapes'][1]['points'])[1]\n",
        "            \n",
        "            np.divide(coords, [640,480,640,480])\n",
        "                \n",
        "        try: \n",
        "            for x in range(120):\n",
        "                keypoints = [(coords[:2]), (coords[2:])]\n",
        "                augmented = augmentor(image=img, keypoints=keypoints, class_labels=['LeftEye','RightEye'])\n",
        "                cv2.imwrite(os.path.join('aug_data', partition, 'images', f'{image.split(\".\")[0]}.{x}.jpg'), augmented['image'])\n",
        "\n",
        "                annotation = {}\n",
        "                annotation['image'] = image\n",
        "                annotation['class'] = [0,0]\n",
        "                annotation['keypoints'] = [0,0,0,0]\n",
        "\n",
        "                if os.path.exists(label_path):\n",
        "                    if len(augmented['keypoints']) > 0: \n",
        "                        for idx, cl in enumerate(augmented['class_labels']):\n",
        "                            if cl == 'LeftEye': \n",
        "                                annotation['class'][0] = 1 \n",
        "                                annotation['keypoints'][0] = augmented['keypoints'][idx][0]\n",
        "                                annotation['keypoints'][1] = augmented['keypoints'][idx][1]\n",
        "                            if cl == 'RightEye': \n",
        "                                annotation['class'][1] = 1 \n",
        "                                annotation['keypoints'][2] = augmented['keypoints'][idx][0]\n",
        "                                annotation['keypoints'][3] = augmented['keypoints'][idx][1]\n",
        "                                \n",
        "                annotation['keypoints'] = list(np.divide(annotation['keypoints'], [450,450,450,450]))\n",
        "\n",
        "\n",
        "                with open(os.path.join('aug_data', partition, 'labels', f'{image.split(\".\")[0]}.{x}.json'), 'w') as f:\n",
        "                    json.dump(annotation, f)\n",
        "\n",
        "        except Exception as e:\n",
        "            print(e)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 235
        },
        "id": "OdPrAUZx6pg5",
        "outputId": "d362d790-b204-4d44-df54-e27417cbaeb4"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-23-c0f8c8d10b67>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mpartition\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'train'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'test'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'val'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mimage\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'data'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpartition\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'images'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m         \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'data'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpartition\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'images'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0mclasses\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'data/train/images'"
          ]
        }
      ]
    }
  ]
}